{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries Used in Data Preparation\n",
    "import pandas as pd\n",
    "import os\n",
    "debug = True\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to Load Data in a DataFrame\n",
    "datafolder = '../data/'\n",
    "#print(os.listdir(datafolder))\n",
    "train_features_file_name = 'train_features.csv'\n",
    "train_labels_file_name = 'train_salaries.csv'\n",
    "test_features_file_name = 'test_features.csv'\n",
    "\n",
    "# with open(os.path.join(datafolder, test_features_file_name)) as f:\n",
    "#     x = f.readlines()\n",
    "# print(x[1])\n",
    "train_data_features = pd.read_csv(os.path.join(datafolder, train_features_file_name))\n",
    "org_features = train_data_features.columns.tolist()\n",
    "train_data_labels = pd.read_csv(os.path.join(datafolder, train_labels_file_name))\n",
    "train_full = pd.merge(train_data_features, train_data_labels, on='jobId',how ='inner')\n",
    "test_data_features = pd.read_csv(os.path.join(datafolder, test_features_file_name))\n",
    "\n",
    "assert(train_full.shape[0] == train_data_features.shape[0])\n",
    "assert(train_full.shape[0] == train_data_labels.shape[0])\n",
    "#train_full.dropna(how ='any', inplace = True)\n",
    "train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clean/Check Data (Pending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobId                  0\n",
       "companyId              0\n",
       "jobType                0\n",
       "degree                 0\n",
       "major                  0\n",
       "industry               0\n",
       "yearsExperience        0\n",
       "milesFromMetropolis    0\n",
       "salary                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check train Data for any null values\n",
    "train_full.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobId                  0\n",
       "companyId              0\n",
       "jobType                0\n",
       "degree                 0\n",
       "major                  0\n",
       "industry               0\n",
       "yearsExperience        0\n",
       "milesFromMetropolis    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Test Data for any null values\n",
    "test_data_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** No null values found so no data cleaning performed **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create copie of original train and test data\n",
    "train_full_encoded = train_full\n",
    "test_data_features_encoded = test_data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.3.1 One Hot Encoding : Done for *companyId*, *major*, and *industry* as these variabes are categories and may influence the salary **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OH_companyId', 'OH_major', 'OH_industry']\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Variables One Hot (both test and train)\n",
    "\n",
    "def one_hot_encoding(c, df):\n",
    "    new_f_name = 'OH_'+ c\n",
    "    df = pd.concat([df, pd.get_dummies(df[c], prefix= new_f_name)], axis=1)\n",
    "    return df, new_f_name\n",
    "\n",
    "cat_features_normal = ['companyId', 'major', 'industry']\n",
    "cat_features_normal_new = []\n",
    "for c in cat_features_normal:\n",
    "    train_full_encoded, new_f_name = one_hot_encoding(c, train_full_encoded)\n",
    "    test_data_features_encoded, new_f_name_test = one_hot_encoding(c, test_data_features_encoded)\n",
    "    cat_features_normal_new.append(new_f_name)\n",
    "    \n",
    "    \n",
    "print(cat_features_normal_new)\n",
    "#train_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.3.2 Ordinal  Encoding : Done for *degree* and *jobType* as these variabes have an inherent order associated with them **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pending Visualize data to decide order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORD_jobType', 'ORD_degree']\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Variables Ordered (both test and train)\n",
    "\n",
    "def ordinal_encoding(c, df, lookup):\n",
    "    new_f_name = 'ORD_'+ c\n",
    "    df[new_f_name] =  df[c].map(lookup)\n",
    "    return df, new_f_name\n",
    "\n",
    "degreeOrder = {'BACHELORS':2, 'DOCTORAL':4, 'HIGH_SCHOOL':1, 'MASTERS':3, 'NONE':0}\n",
    "jobTypeOrder = {'CEO':7, 'CFO':6, 'CTO':5, 'VICE_PRESIDENT':4, 'MANAGER':3,'SENIOR':2, 'JUNIOR':1, 'JANITOR':0}\n",
    "\n",
    "cat_features_ordinal = ['jobType', 'degree']\n",
    "cat_features_ordinal_new = []\n",
    "for c in cat_features_ordinal:\n",
    "    train_full_encoded, new_f_name = ordinal_encoding(c, train_full_encoded, eval(c+'Order'))\n",
    "    test_data_features_encoded, new_f_name_test = ordinal_encoding(c, test_data_features_encoded, eval(c+'Order'))\n",
    "    cat_features_ordinal_new.append(new_f_name)\n",
    "\n",
    "print(cat_features_ordinal_new)\n",
    "#train_full.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_categorical_features = cat_features_ordinal + cat_features_normal_new\n",
    "# all_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for c in cat_features_normal:\n",
    "#     print(c)\n",
    "#     test_data_features_encoded, new_f_name_test = one_hot_encoding(c, test_data_features_encoded)\n",
    "\n",
    "# for c in cat_features_ordinal:\n",
    "#     test_data_features_encoded, new_f_name_test = ordinal_encoding(c, test_data_features_encoded, eval(c+'Order'))\n",
    "\n",
    "#print(len(train_full_encoded.columns))\n",
    "#print(len(test_data_features_encoded.columns))\n",
    "#train_full_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Shuffle Data and Split into K folds which are used during model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle Train Data\n",
    "train_full_encoded =  train_full_encoded.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split Data into K Folds\n",
    "from sklearn.model_selection import KFold\n",
    "def GetKFoldData(df,k):\n",
    "    folds = {}\n",
    "    kfolds = KFold(n_splits=k, shuffle = True, random_state = 4) \n",
    "    foldidx = 0\n",
    "    for train_idx, test_idx in kfolds.split(df.index):\n",
    "        folds[foldidx] = { 'train': df.iloc[train_idx], 'test':df.iloc[test_idx]}\n",
    "        foldidx+=1\n",
    "    return folds\n",
    "\n",
    "#exp_data_k_folds = GetKFoldData(train_full, 10)\n",
    "#idx_list_org = exp_data_k_folds[0]['test'].index.tolist()\n",
    "#exp_data_k_folds[0]['test'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set(test_data_features.jobType.tolist())\n",
    "# set(test_data_features.degree.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Set Scaler to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalermain = preprocessing.StandardScaler()\n",
    "#scalermain = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decide Features to Use and Models to Evaluate (Feature Scaling Pending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1.1 Features to be Used (Filtered out encoded variables) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select Features\n",
    "non_cat_features = ['yearsExperience', 'milesFromMetropolis']\n",
    "cat_features =[]\n",
    "for f in train_full_encoded.columns:\n",
    "    if 'OH' in f or 'ORD' in f:\n",
    "        cat_features.append(f)\n",
    "        \n",
    "#train_full[train_features].head()\n",
    "all_features = non_cat_features + cat_features \n",
    "features_to_scale = non_cat_features + cat_features_ordinal_new\n",
    "#train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1.2 Regression Models Considered **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Different Regression Models Evaluated\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "models = {\n",
    "            'LR' :    {'modelobj' :  linear_model.LinearRegression(), 'mse':None, 'rmse':None,\\\n",
    "                                     'tr_time':None,'tst_time':None},\n",
    "    \n",
    "            'Ridge' : {'modelobj' :  linear_model.Ridge(), 'mse':None, 'rmse':None,\\\n",
    "                                     'tr_time':None,'tst_time':None,\\\n",
    "                                     'params' : {'alpha': [i for i in range(1,81,3)]}},\n",
    "    \n",
    "            'DT' :    {'modelobj' :  DecisionTreeRegressor(random_state=10), 'mse':None, 'rmse':None, \\\n",
    "                                     'tr_time':None,'tst_time':None, \\\n",
    "                                     'params' : {\n",
    "                                                 'max_depth':[i for i in range(9,12)], \\\n",
    "                                                 'min_samples_leaf' :[i for i in range(10,21,5)]\n",
    "                                                }}#,   \n",
    "    \n",
    "#             'RF' :    {'modelobj' :  RandomForestRegressor(random_state=10), 'mse':None, 'rmse':None, \\\n",
    "#                                      'tr_time':None,'tst_time':None, \\\n",
    "#                                      'params' : {\n",
    "#                                                  'n_estimators':[i for i in range(300,501,100)],\n",
    "#                                                  'max_depth':[i for i in range(9,12)], \n",
    "#                                                  'min_samples_leaf' :[i for i in range(10,21,5)],\n",
    "#                                                  'max_features' : ['log2', 'sqrt']\n",
    "#                                                  }}\n",
    "        \n",
    "            #'GBR' : {'modelobj' :  GradientBoostingRegressor(), 'mse':None, 'rmse':None}\n",
    "         \n",
    "         }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions to Evaluate a Model given train and test data\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "def EvalModelSplitData(m, model, curr_fold, all_features, features_to_scale, \\\n",
    "                       scaler = preprocessing.StandardScaler()):\n",
    "    \n",
    "    #Train Data Selection\n",
    "    curr_fold_X_train = curr_fold['train'][all_features]\n",
    "    curr_fold_X_train_scaled= curr_fold_X_train\n",
    "    curr_fold_X_train_scaled[features_to_scale] = scaler.fit_transform(curr_fold_X_train[features_to_scale])\n",
    "    curr_fold_y_train = curr_fold['train']['salary'] \n",
    "    \n",
    "    tr_st = time.time()\n",
    "    curr_model = model['modelobj'].fit(curr_fold_X_train_scaled, curr_fold_y_train)\n",
    "    tr_time = time.time() - tr_st\n",
    "    \n",
    "    \n",
    "    #Test\n",
    "    curr_fold_X_test = curr_fold['test'][all_features]\n",
    "    curr_fold_X_test_scaled = curr_fold_X_test\n",
    "    curr_fold_X_test_scaled[features_to_scale] = scaler.fit_transform(curr_fold_X_test[features_to_scale])\n",
    "    curr_fold_y_test = curr_fold['test']['salary']\n",
    "    \n",
    "    tst_st = time.time()\n",
    "    curr_test_predict = curr_model.predict(curr_fold_X_test_scaled)\n",
    "    tst_time = time.time() - tst_st\n",
    "    \n",
    "    #Compute Cost (MSE/RMSE)\n",
    "    curr_fold_mse = MSE(curr_test_predict, curr_fold_y_test)\n",
    "    curr_fold_rmse = curr_fold_mse**0.5\n",
    "    \n",
    "    return curr_fold_mse, curr_fold_rmse, tr_time, tst_time\n",
    "    \n",
    "\n",
    "def GetBestParams(m, model, alldata, all_features, features_to_scale, k,\\\n",
    "                  scaler = preprocessing.StandardScaler()):\n",
    "                  \n",
    "    X_train = alldata[all_features]\n",
    "    y_train = alldata['salary']\n",
    "    X_train_scaled = X_train\n",
    "    X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "    \n",
    "    \n",
    "    if m in ['Ridge','DT']:\n",
    "        model_search = GridSearchCV(model['modelobj'], model['params'], cv=k, verbose=0, n_jobs=-1,\\\n",
    "                                    scoring ='neg_mean_squared_error')\n",
    "        model_search.fit(X_train_scaled, y_train)\n",
    "        best_model = model_search.best_estimator_\n",
    "        return best_model\n",
    "    elif m in ['RF','GBR']:\n",
    "        model_search = GridSearchCV(model['modelobj'], model['params'],verbose=0, n_jobs=-1,\\\n",
    "                                    scoring ='neg_mean_squared_error')\n",
    "        model_search.fit(X_train_scaled, y_train)\n",
    "        best_model = model_search.best_estimator_\n",
    "        return best_model\n",
    "    else:\n",
    "        return model['modelobj']        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.2.1 Run Grid Search on all models to get initial best performing parameters **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Best Params for :  LR\n",
      "Best Params Found for :  LR\n",
      "\n",
      "Finding Best Params for :  Ridge\n",
      "Best Params Found for :  Ridge\n",
      "\n",
      "Finding Best Params for :  DT\n",
      "Best Params Found for :  DT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get Model Params Using Grid Search CV\n",
    "\n",
    "def RunExpOnAllData(models,all_features,features_to_scale, alldata, sc = preprocessing.StandardScaler()):\n",
    "    for m in models:\n",
    "        print('Finding Best Params for : ', m)\n",
    "        models[m]['modelobj'] = GetBestParams(m, models[m], alldata, all_features,features_to_scale, 5, sc)\n",
    "        print('Best Params Found for : ', m)\n",
    "        print()\n",
    "\n",
    "\n",
    "RunExpOnAllData(models, all_features,features_to_scale, train_full_encoded, scalermain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.2.2  Evaluate all models to see what perfoms best on differnt folds created in 1.4 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tr_time</th>\n",
       "      <th>tst_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>422.489307</td>\n",
       "      <td>20.554496</td>\n",
       "      <td>15.463073</td>\n",
       "      <td>0.065653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>394.548262</td>\n",
       "      <td>19.863205</td>\n",
       "      <td>5.126561</td>\n",
       "      <td>0.066280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>394.546563</td>\n",
       "      <td>19.863162</td>\n",
       "      <td>1.425829</td>\n",
       "      <td>0.050720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mse       rmse    tr_time  tst_time\n",
       "DT     422.489307  20.554496  15.463073  0.065653\n",
       "LR     394.548262  19.863205   5.126561  0.066280\n",
       "Ridge  394.546563  19.863162   1.425829  0.050720"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find model performance vased on k-fold data created earliers ( See 1.4)\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "def RunExpOnSplitData(kfolddata, models, all_features,features_to_scale, sc = preprocessing.StandardScaler()):\n",
    "    for m in models:\n",
    "        pool = mp.Pool(mp.cpu_count() -1 )\n",
    "        #mse_rmse_results = pool.starmap(EvalModel, [ (models[m], kfolddata[curr_fold], train_features) for curr_fold in kfolddata])\n",
    "        mse_rmse_results = pool.starmap_async(EvalModelSplitData, [(m, models[m], kfolddata[curr_fold], all_features,features_to_scale, sc) for curr_fold in kfolddata]).get()\n",
    "        pool.close()\n",
    "    \n",
    "        models[m]['mse'] = sum([i[0] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['rmse'] = sum([i[1] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['tr_time'] = sum([i[2] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['tst_time'] = sum([i[3] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        \n",
    "        #print(m, models[m]['mse'], models[m]['rmse'],models[m]['tr_time'],models[m]['tst_time'], k)              \n",
    "\n",
    "k = 10\n",
    "kfolddata =  GetKFoldData(train_full_encoded, k)    \n",
    "RunExpOnSplitData(kfolddata, models, all_features,features_to_scale, scalermain)\n",
    "models_df =  pd.DataFrame.from_dict(models, orient='index')\n",
    "models_df[['mse','rmse','tr_time','tst_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Based on above resuts the  *Ridge* regression model will be used for further experiments in this notebook **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.2.3  Choose the model to be used **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge  is the model choosen\n"
     ]
    }
   ],
   "source": [
    "#Choose Model Having the least RMSE on average over k-fold data\n",
    "modelchosen = ('LR',models['LR'])\n",
    "for m in models:\n",
    "    if models[m]['rmse']<modelchosen[1]['rmse']:\n",
    "        modelchosen = (m,models[m])\n",
    "\n",
    "print(modelchosen[0], ' is the model choosen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#modelchosen = ('LR',models['LR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COmmented\n",
    "\n",
    "# curr_model_mse = 0 \n",
    "# curr_model_rmse = 0                 \n",
    "#         for curr_fold in kfolddata:\n",
    "#             curr_fold_mse, curr_fold_rmse = EvalModel(models[m], kfolddata[curr_fold], train_features)\n",
    "#             print(m, curr_fold_mse, curr_fold_rmse)\n",
    "#             curr_model_mse += curr_fold_mse\n",
    "#             curr_model_rmse += curr_fold_rmse\n",
    "\n",
    "#         models[m]['mse']  = curr_model_mse/k\n",
    "#         models[m]['rmse'] = curr_model_rmse/k\n",
    "#         print(m, models[m]['mse'], models[m]['rmse'], k)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Importance w.r.t best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the best performing model I have tried to measure feature importance based on the impact they cause when the feature has been removed. (I have removed the features from the original category and not the encoded ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Features whose importance is to be checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['companyId',\n",
       " 'jobType',\n",
       " 'degree',\n",
       " 'major',\n",
       " 'industry',\n",
       " 'yearsExperience',\n",
       " 'milesFromMetropolis']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Features whose importance will be evaluated\n",
    "org_features = org_features[1:]\n",
    "org_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Remove each feature at a time and compute/display the percentage increase in RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check change in RMSE performance on k-fold data when a feature is excluded for the best performig model\n",
    "feature_imp_results = {}\n",
    "\n",
    "# IF required feature importance can be checked over all the models also\n",
    "#for m in models:\n",
    "#    modelchosen = (m, models[m])\n",
    "\n",
    "for f in org_features:\n",
    "    try:\n",
    "\n",
    "        all_features_wo_curr_f = [of for of in all_features if f not in of]\n",
    "        features_to_scale_wo_curr_f = [of for of in features_to_scale if f not in of]         \n",
    "\n",
    "        pool = mp.Pool(mp.cpu_count() -1 )\n",
    "        mse_rmse_results = pool.starmap_async(EvalModelSplitData, [(modelchosen[0], modelchosen[1], kfolddata[curr_fold], all_features_wo_curr_f, features_to_scale_wo_curr_f, scalermain) \\\n",
    "                                                                   for curr_fold in kfolddata]).get()\n",
    "        pool.close()\n",
    "        if f not in feature_imp_results:\n",
    "            feature_imp_results[f] = {}\n",
    "            feature_imp_results[f]['Model'] = modelchosen[0]\n",
    "            feature_imp_results[f]['mse'] = sum([i[0] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "            feature_imp_results[f]['rmse'] = sum([i[1] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "            feature_imp_results[f]['org_rmse'] = modelchosen[1]['rmse']\n",
    "            feature_imp_results[f]['Percentage_increase_RMSE'] = 100 * (feature_imp_results[f]['rmse'] - modelchosen[1]['rmse'])/modelchosen[1]['rmse']\n",
    "    except:\n",
    "        print('Exception occured while evlaluation importance of eature', f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>org_rmse</th>\n",
       "      <th>Percentage_increase_RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Removed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jobType</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>774.515048</td>\n",
       "      <td>27.830035</td>\n",
       "      <td>19.863162</td>\n",
       "      <td>40.108784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsExperience</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>604.825222</td>\n",
       "      <td>24.593140</td>\n",
       "      <td>19.863162</td>\n",
       "      <td>23.812810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milesFromMetropolis</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>527.661478</td>\n",
       "      <td>22.970828</td>\n",
       "      <td>19.863162</td>\n",
       "      <td>15.645371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>524.687694</td>\n",
       "      <td>22.905979</td>\n",
       "      <td>19.863162</td>\n",
       "      <td>15.318894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>414.592020</td>\n",
       "      <td>20.361503</td>\n",
       "      <td>19.863162</td>\n",
       "      <td>2.508869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>411.535307</td>\n",
       "      <td>20.286289</td>\n",
       "      <td>19.863162</td>\n",
       "      <td>2.130207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>companyId</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>394.517292</td>\n",
       "      <td>19.862426</td>\n",
       "      <td>19.863162</td>\n",
       "      <td>-0.003709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model         mse       rmse   org_rmse  \\\n",
       "Feature Removed                                                \n",
       "jobType              Ridge  774.515048  27.830035  19.863162   \n",
       "yearsExperience      Ridge  604.825222  24.593140  19.863162   \n",
       "milesFromMetropolis  Ridge  527.661478  22.970828  19.863162   \n",
       "industry             Ridge  524.687694  22.905979  19.863162   \n",
       "degree               Ridge  414.592020  20.361503  19.863162   \n",
       "major                Ridge  411.535307  20.286289  19.863162   \n",
       "companyId            Ridge  394.517292  19.862426  19.863162   \n",
       "\n",
       "                     Percentage_increase_RMSE  \n",
       "Feature Removed                                \n",
       "jobType                             40.108784  \n",
       "yearsExperience                     23.812810  \n",
       "milesFromMetropolis                 15.645371  \n",
       "industry                            15.318894  \n",
       "degree                               2.508869  \n",
       "major                                2.130207  \n",
       "companyId                           -0.003709  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display how much is the increase in error when a feature is dropped\n",
    "feature_imp_results_df = pd.DataFrame.from_dict(feature_imp_results, orient='index')\n",
    "feature_imp_results_df.index.name = 'Feature Removed'\n",
    "feature_imp_results_df.sort_values(by='Percentage_increase_RMSE', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** From above resuts it is evident that *JobType* has the most predictive power whereas the feature *companyId* has the least predicitve power **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature_imp = feature_imp_results_df.groupby('Model')\n",
    "# feature_imp.sort_values(by='percentage_error_increase', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict Salaries for Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prediction of salaries is made for the test data based on the best model chosen above. The test data has been already been encoded in the same way as before and the scaling of numerica features is same as performed with the trianing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Predict Salaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0,
     1,
     17
    ]
   },
   "outputs": [],
   "source": [
    "#Helper Function to Predict Salaries Given testdata, model and scaling scheme\n",
    "def PredictSalary(m, model, test_data, all_features, features_to_scale, \\\n",
    "                       scaler = preprocessing.StandardScaler()):\n",
    "        \n",
    "    #Test\n",
    "    X_test = test_data[all_features]\n",
    "    X_test_scaled = X_test\n",
    "    X_test_scaled[features_to_scale] = scaler.fit_transform(test_data[features_to_scale])\n",
    "    \n",
    "    tst_st = time.time()\n",
    "    test_predictions = model.predict(X_test_scaled)\n",
    "    tst_time = time.time() - tst_st\n",
    "    \n",
    "    test_data['salary'] = test_predictions \n",
    "    \n",
    "    return test_data\n",
    "\n",
    "def get_currtime_str():\n",
    "    from datetime import datetime\n",
    "    \"\"\" Gets the current time in a particular format  \"\"\"\n",
    "\n",
    "    timestampformat = '%Y%m%d__%H%M%S'\n",
    "    currtime_str = str(datetime.now().strftime(timestampformat))\n",
    "    return currtime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Predict Salaries of Test Data Based on Chosen Model and save the predictions in a csv file\n",
    "test_salaries = PredictSalary(modelchosen[0], modelchosen[1]['modelobj'], test_data_features_encoded, all_features, features_to_scale, \\\n",
    "                          scalermain)\n",
    "assert(test_salaries.shape[0]==test_data_features_encoded.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Save predicted salaries to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Predicted Salaries for test data saved in file  20190325__222550_test_salaries.csv\n"
     ]
    }
   ],
   "source": [
    "currtime = get_currtime_str()\n",
    "test_salaries[['jobId','salary']].to_csv(currtime+'_test_salaries.csv', index = False)\n",
    "print(\" Predicted Salaries for test data saved in file \", currtime+'_test_salaries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Estimating RMSE of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Similarity betweeen test data jobs and training data jobs\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "import scipy \n",
    "\n",
    "#Get Scaled Data\n",
    "train_full_encoded_scaled = train_full_encoded\n",
    "test_data_features_encoded_scaled = test_data_features_encoded.iloc[0:100]\n",
    "\n",
    "\n",
    "train_full_encoded_scaled[features_to_scale] = scalermain.fit_transform(train_full_encoded_scaled[features_to_scale])\n",
    "test_data_features_encoded_scaled[features_to_scale] = scalermain.fit_transform(test_data_features_encoded_scaled[features_to_scale])\n",
    "\n",
    "\n",
    "#Create Sparse Matrices of Train and Test Data\n",
    "TRNG_MAT = scipy.sparse.csr_matrix(train_full_encoded_scaled[all_features].values)\n",
    "TST_MAT = scipy.sparse.csr_matrix(test_data_features_encoded_scaled[all_features].values)\n",
    "sim = cosine_similarity(TST_MAT, TRNG_MAT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of most similar row in Training data w.r.t each row in test data\n",
    "max_idx_list = np.argmax(sim, axis=1).tolist()\n",
    "test_data_features_encoded_scaled['most_similar_row'] = max_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the salary of each row in test data as equal to the salary of most similar row in traning_data\n",
    "def getSalFromTrainData(rowidx,trdata):\n",
    "    return trdata.iloc[rowidx]['salary']\n",
    "\n",
    "test_data_features_encoded['most_similar_salary'] =\\\n",
    "    test_data_features_encoded_scaled['most_similar_row'].apply(getSalFromTrainData, args=( train_full_encoded,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_features_encoded_scaled['most_similar_salary']\n",
    "#test_data_features_encoded = PredictSalary(modelchosen[0], modelchosen[1]['modelobj'], test_data_features_encoded, all_features, features_to_scale, \\\n",
    "#                         scalermain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.638664311595964"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute RMSE based on the most similar salary (as found above) vs predcited salary as computed based on best performing model\n",
    "predicted_mse = MSE(test_data_features_encoded['salary'].tolist()[0:100],\\\n",
    "                    test_data_features_encoded['most_similar_salary'].tolist()[0:100])\n",
    "predicted_rmse = predicted_mse**0.5\n",
    "predicted_rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

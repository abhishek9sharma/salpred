{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries Used in Data Preparation\n",
    "import pandas as pd\n",
    "import os\n",
    "debug = True\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load Data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to Load Data in a DataFrame\n",
    "datafolder = '../data/'\n",
    "#print(os.listdir(datafolder))\n",
    "train_features_file_name = 'train_features.csv'\n",
    "train_labels_file_name = 'train_salaries.csv'\n",
    "test_features_file_name = 'test_features.csv'\n",
    "\n",
    "# with open(os.path.join(datafolder, test_features_file_name)) as f:\n",
    "#     x = f.readlines()\n",
    "# print(x[1])\n",
    "train_data_features = pd.read_csv(os.path.join(datafolder, train_features_file_name))\n",
    "org_features = train_data_features.columns.tolist()\n",
    "train_data_labels = pd.read_csv(os.path.join(datafolder, train_labels_file_name))\n",
    "train_full = pd.merge(train_data_features, train_data_labels, on='jobId',how ='inner')\n",
    "test_data_features = pd.read_csv(os.path.join(datafolder, test_features_file_name))\n",
    "\n",
    "assert(train_full.shape[0] == train_data_features.shape[0])\n",
    "assert(train_full.shape[0] == train_data_labels.shape[0])\n",
    "#train_full.dropna(how ='any', inplace = True)\n",
    "train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jobId',\n",
       " 'companyId',\n",
       " 'jobType',\n",
       " 'degree',\n",
       " 'major',\n",
       " 'industry',\n",
       " 'yearsExperience',\n",
       " 'milesFromMetropolis']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000000\n",
    "# 1000000\n",
    "org_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Clean/Check Data (Pending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_full.describe()\n",
    "train_full.isnull().sum()\n",
    "train_full_encoded = train_full\n",
    "test_data_features_encoded= test_data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 One Hot Encoding : Done for *companyId*, *major*, and *industry* as these variabes are categories and may influence the salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OH_companyId', 'OH_major', 'OH_industry']\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Variables One Hot\n",
    "\n",
    "def one_hot_encoding(c, df):\n",
    "    new_f_name = 'OH_'+ c\n",
    "    df = pd.concat([df, pd.get_dummies(df[c], prefix= new_f_name)], axis=1)\n",
    "    return df, new_f_name\n",
    "\n",
    "cat_features_normal = ['companyId', 'major', 'industry']\n",
    "cat_features_normal_new = []\n",
    "for c in cat_features_normal:\n",
    "    train_full_encoded, new_f_name = one_hot_encoding(c, train_full_encoded)\n",
    "    test_data_features_encoded, new_f_name_test = one_hot_encoding(c, test_data_features_encoded)\n",
    "    cat_features_normal_new.append(new_f_name)\n",
    "    \n",
    "    \n",
    "print(cat_features_normal_new)\n",
    "#train_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Ordinal  Encoding : Done for *degree* and *jobType* as these variabes have an inherent order associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pending Visualize data to decide order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORD_jobType', 'ORD_degree']\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Variables Ordered\n",
    "\n",
    "def ordinal_encoding(c, df, lookup):\n",
    "    new_f_name = 'ORD_'+ c\n",
    "    df[new_f_name] =  df[c].map(lookup)\n",
    "    return df, new_f_name\n",
    "\n",
    "degreeOrder = {'BACHELORS':2, 'DOCTORAL':4, 'HIGH_SCHOOL':1, 'MASTERS':3, 'NONE':0}\n",
    "jobTypeOrder = {'CEO':7, 'CFO':6, 'CTO':5, 'VICE_PRESIDENT':4, 'MANAGER':3,'SENIOR':2, 'JUNIOR':1, 'JANITOR':0}\n",
    "\n",
    "cat_features_ordinal = ['jobType', 'degree']\n",
    "cat_features_ordinal_new = []\n",
    "for c in cat_features_ordinal:\n",
    "    train_full_encoded, new_f_name = ordinal_encoding(c, train_full_encoded, eval(c+'Order'))\n",
    "    test_data_features_encoded, new_f_name_test = ordinal_encoding(c, test_data_features_encoded, eval(c+'Order'))\n",
    "    cat_features_ordinal_new.append(new_f_name)\n",
    "\n",
    "print(cat_features_ordinal_new)\n",
    "#train_full.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jobType', 'degree', 'OH_companyId', 'OH_major', 'OH_industry']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categorical_features = cat_features_ordinal + cat_features_normal_new\n",
    "all_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for c in cat_features_normal:\n",
    "#     print(c)\n",
    "#     test_data_features_encoded, new_f_name_test = one_hot_encoding(c, test_data_features_encoded)\n",
    "\n",
    "# for c in cat_features_ordinal:\n",
    "#     test_data_features_encoded, new_f_name_test = ordinal_encoding(c, test_data_features_encoded, eval(c+'Order'))\n",
    "\n",
    "#print(len(train_full_encoded.columns))\n",
    "#print(len(test_data_features_encoded.columns))\n",
    "#train_full_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Shuffle Data and Split into K folds which are used during model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle Train Data\n",
    "train_full_encoded =  train_full_encoded.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split Data into K Folds\n",
    "from sklearn.model_selection import KFold\n",
    "def GetKFoldData(df,k):\n",
    "    folds = {}\n",
    "    kfolds = KFold(n_splits=k, shuffle = True, random_state = 4) \n",
    "    foldidx = 0\n",
    "    for train_idx, test_idx in kfolds.split(df.index):\n",
    "        folds[foldidx] = { 'train': df.iloc[train_idx], 'test':df.iloc[test_idx]}\n",
    "        foldidx+=1\n",
    "    return folds\n",
    "\n",
    "#exp_data_k_folds = GetKFoldData(train_full, 10)\n",
    "#idx_list_org = exp_data_k_folds[0]['test'].index.tolist()\n",
    "#exp_data_k_folds[0]['test'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set(test_data_features.jobType.tolist())\n",
    "# set(test_data_features.degree.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalermain = preprocessing.StandardScaler()\n",
    "#scalermain = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Decide Features to Use and Models to Evaluate (Feature Scaling Pending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1 Features to be Used (Filtered out encoded variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select Features\n",
    "non_cat_features = ['yearsExperience', 'milesFromMetropolis']\n",
    "cat_features =[]\n",
    "for f in train_full_encoded.columns:\n",
    "    if 'OH' in f or 'ORD' in f:\n",
    "        cat_features.append(f)\n",
    "        \n",
    "#train_full[train_features].head()\n",
    "all_features = non_cat_features + cat_features \n",
    "features_to_scale = non_cat_features + cat_features_ordinal_new\n",
    "#train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 Regression Models Considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Different Regression Models Evaluated\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "models = {\n",
    "            'LR' :    {'modelobj' :  linear_model.LinearRegression(), 'mse':None, 'rmse':None,\\\n",
    "                                     'tr_time':None,'tst_time':None},\n",
    "    \n",
    "            'Ridge' : {'modelobj' :  linear_model.Ridge(), 'mse':None, 'rmse':None,\\\n",
    "                                     'tr_time':None,'tst_time':None,\\\n",
    "                                     'params' : {'alpha': [i for i in range(1,81,3)]}},\n",
    "    \n",
    "            'DT' :    {'modelobj' :  DecisionTreeRegressor(random_state=10), 'mse':None, 'rmse':None, \\\n",
    "                                     'tr_time':None,'tst_time':None, \\\n",
    "                                     'params' : {\n",
    "                                                 'max_depth':[i for i in range(9,12)], \\\n",
    "                                                 'min_samples_leaf' :[i for i in range(10,21,5)]\n",
    "                                                }}#,   \n",
    "    \n",
    "#             'RF' :    {'modelobj' :  RandomForestRegressor(random_state=10), 'mse':None, 'rmse':None, \\\n",
    "#                                      'tr_time':None,'tst_time':None, \\\n",
    "#                                      'params' : {\n",
    "#                                                  'n_estimators':[i for i in range(300,501,100)],\n",
    "#                                                  'max_depth':[i for i in range(9,12)], \n",
    "#                                                  'min_samples_leaf' :[i for i in range(10,21,5)],\n",
    "#                                                  'max_features' : ['log2', 'sqrt']\n",
    "#                                                  }}\n",
    "        \n",
    "            #'GBR' : {'modelobj' :  GradientBoostingRegressor(), 'mse':None, 'rmse':None}\n",
    "         \n",
    "         }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions to Evaluate a Model given train and test data\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "def EvalModelSplitData(m, model, curr_fold, all_features, features_to_scale, \\\n",
    "                       scaler = preprocessing.StandardScaler()):\n",
    "    \n",
    "    #Train Data Selection\n",
    "    curr_fold_X_train = curr_fold['train'][all_features]\n",
    "    curr_fold_X_train_scaled= curr_fold_X_train\n",
    "    curr_fold_X_train_scaled[features_to_scale] = scaler.fit_transform(curr_fold_X_train[features_to_scale])\n",
    "    curr_fold_y_train = curr_fold['train']['salary'] \n",
    "    \n",
    "    tr_st = time.time()\n",
    "    curr_model = model['modelobj'].fit(curr_fold_X_train_scaled, curr_fold_y_train)\n",
    "    tr_time = time.time() - tr_st\n",
    "    \n",
    "    \n",
    "    #Test\n",
    "    curr_fold_X_test = curr_fold['test'][all_features]\n",
    "    curr_fold_X_test_scaled = curr_fold_X_test\n",
    "    curr_fold_X_test_scaled[features_to_scale] = scaler.fit_transform(curr_fold_X_test[features_to_scale])\n",
    "    curr_fold_y_test = curr_fold['test']['salary']\n",
    "    \n",
    "    tst_st = time.time()\n",
    "    curr_test_predict = curr_model.predict(curr_fold_X_test_scaled)\n",
    "    tst_time = time.time() - tst_st\n",
    "    \n",
    "    #Compute Cost (MSE/RMSE)\n",
    "    curr_fold_mse = MSE(curr_test_predict, curr_fold_y_test)\n",
    "    curr_fold_rmse = curr_fold_mse**0.5\n",
    "    \n",
    "    return curr_fold_mse, curr_fold_rmse, tr_time, tst_time\n",
    "    \n",
    "\n",
    "def GetBestParams(m, model, alldata, all_features, features_to_scale, k,\\\n",
    "                  scaler = preprocessing.StandardScaler()):\n",
    "                  \n",
    "    X_train = alldata[all_features]\n",
    "    y_train = alldata['salary']\n",
    "    X_train_scaled = X_train\n",
    "    X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "    \n",
    "    \n",
    "    if m in ['Ridge','DT']:\n",
    "        model_search = GridSearchCV(model['modelobj'], model['params'], cv=k, verbose=0, n_jobs=-1,\\\n",
    "                                    scoring ='neg_mean_squared_error')\n",
    "        model_search.fit(X_train_scaled, y_train)\n",
    "        best_model = model_search.best_estimator_\n",
    "        return best_model\n",
    "    elif m in ['RF','GBR']:\n",
    "        model_search = GridSearchCV(model['modelobj'], model['params'],verbose=0, n_jobs=-1,\\\n",
    "                                    scoring ='neg_mean_squared_error')\n",
    "        model_search.fit(X_train_scaled, y_train)\n",
    "        best_model = model_search.best_estimator_\n",
    "        return best_model\n",
    "    else:\n",
    "        return model['modelobj']        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 Run Grid Search on all models to get initial best performing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finding Best Params\n",
      "LR Best Params Found\n",
      "Ridge Finding Best Params\n",
      "Ridge Best Params Found\n",
      "DT Finding Best Params\n",
      "DT Best Params Found\n"
     ]
    }
   ],
   "source": [
    "#Get Model Params Using Grid Search CV\n",
    "\n",
    "def RunExpOnAllData(models,all_features,features_to_scale, alldata, sc = preprocessing.StandardScaler()):\n",
    "    for m in models:\n",
    "        print(m,'Finding Best Params')\n",
    "        models[m]['modelobj'] = GetBestParams(m, models[m], alldata, all_features,features_to_scale, 5, sc)\n",
    "        print(m,'Best Params Found')\n",
    "        \n",
    "\n",
    "\n",
    "RunExpOnAllData(models, all_features,features_to_scale, train_full_encoded, scalermain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2  Evaluate all models to see what perfoms best on differnt folds created in 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tr_time</th>\n",
       "      <th>tst_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>422.108463</td>\n",
       "      <td>20.545234</td>\n",
       "      <td>15.409462</td>\n",
       "      <td>0.062072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>394.543680</td>\n",
       "      <td>19.863039</td>\n",
       "      <td>5.450826</td>\n",
       "      <td>0.094322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>394.539984</td>\n",
       "      <td>19.862946</td>\n",
       "      <td>1.413677</td>\n",
       "      <td>0.056092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mse       rmse    tr_time  tst_time\n",
       "DT     422.108463  20.545234  15.409462  0.062072\n",
       "LR     394.543680  19.863039   5.450826  0.094322\n",
       "Ridge  394.539984  19.862946   1.413677  0.056092"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find model performance vased on k-fold data created earliers ( See 1.4)\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "def RunExpOnSplitData(kfolddata, models, all_features,features_to_scale, sc = preprocessing.StandardScaler()):\n",
    "    for m in models:\n",
    "        pool = mp.Pool(mp.cpu_count() -1 )\n",
    "        #mse_rmse_results = pool.starmap(EvalModel, [ (models[m], kfolddata[curr_fold], train_features) for curr_fold in kfolddata])\n",
    "        mse_rmse_results = pool.starmap_async(EvalModelSplitData, [(m, models[m], kfolddata[curr_fold], all_features,features_to_scale, sc) for curr_fold in kfolddata]).get()\n",
    "        pool.close()\n",
    "    \n",
    "        models[m]['mse'] = sum([i[0] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['rmse'] = sum([i[1] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['tr_time'] = sum([i[2] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['tst_time'] = sum([i[3] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        \n",
    "        #print(m, models[m]['mse'], models[m]['rmse'],models[m]['tr_time'],models[m]['tst_time'], k)              \n",
    "\n",
    "k = 10\n",
    "kfolddata =  GetKFoldData(train_full_encoded, k)    \n",
    "RunExpOnSplitData(kfolddata, models, all_features,features_to_scale, scalermain)\n",
    "models_df =  pd.DataFrame.from_dict(models, orient='index')\n",
    "models_df[['mse','rmse','tr_time','tst_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2  Choose the model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge  is the model choosen\n"
     ]
    }
   ],
   "source": [
    "#Choose Model Having the least RMSE on average over k-fold data\n",
    "modelchosen = ('LR',models['LR'])\n",
    "for m in models:\n",
    "    if models[m]['rmse']<modelchosen[1]['rmse']:\n",
    "        modelchosen = (m,models[m])\n",
    "\n",
    "print(modelchosen[0], ' is the model choosen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#modelchosen = ('LR',models['LR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COmmented\n",
    "\n",
    "# curr_model_mse = 0 \n",
    "# curr_model_rmse = 0                 \n",
    "#         for curr_fold in kfolddata:\n",
    "#             curr_fold_mse, curr_fold_rmse = EvalModel(models[m], kfolddata[curr_fold], train_features)\n",
    "#             print(m, curr_fold_mse, curr_fold_rmse)\n",
    "#             curr_model_mse += curr_fold_mse\n",
    "#             curr_model_rmse += curr_fold_rmse\n",
    "\n",
    "#         models[m]['mse']  = curr_model_mse/k\n",
    "#         models[m]['rmse'] = curr_model_rmse/k\n",
    "#         print(m, models[m]['mse'], models[m]['rmse'], k)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Importance w.r.t best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the best performing model I have tried to measure feature importance based on the impact they cause when the feature has been removed. (I have removed the features from the original category and not the encoded ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['companyId',\n",
       " 'jobType',\n",
       " 'degree',\n",
       " 'major',\n",
       " 'industry',\n",
       " 'yearsExperience',\n",
       " 'milesFromMetropolis']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Features whose importance will be evaluated\n",
    "#org_features = ['companyId', 'jobType', 'degree', 'major', 'industry','yearsExperience', 'milesFromMetropolis']\n",
    "#train_features\n",
    "org_features = org_features[1:]\n",
    "org_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Check change in RMSE performance on k-fold data when a feature is excluded\n",
    "feature_imp_results = {}\n",
    "#for m in models:\n",
    "#    modelchosen = (m, models[m])\n",
    "for f in org_features:\n",
    "    try:\n",
    "\n",
    "        all_features_wo_curr_f = [of for of in all_features if f not in of]\n",
    "        features_to_scale_wo_curr_f = [of for of in features_to_scale if f not in of]         \n",
    "\n",
    "        pool = mp.Pool(mp.cpu_count() -1 )\n",
    "        mse_rmse_results = pool.starmap_async(EvalModelSplitData, [(modelchosen[0], modelchosen[1], kfolddata[curr_fold], all_features_wo_curr_f, features_to_scale_wo_curr_f, scalermain) \\\n",
    "                                                                   for curr_fold in kfolddata]).get()\n",
    "        pool.close()\n",
    "        if f not in feature_imp_results:\n",
    "            feature_imp_results[f] = {}\n",
    "            feature_imp_results[f]['Model'] = modelchosen[0]\n",
    "            feature_imp_results[f]['mse'] = sum([i[0] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "            feature_imp_results[f]['rmse'] = sum([i[1] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "            feature_imp_results[f]['percentage_error_increase'] = 100 * (feature_imp_results[f]['rmse'] - modelchosen[1]['rmse'])/modelchosen[1]['rmse']\n",
    "    except:\n",
    "        print('issued with feature', f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>percentage_error_increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jobType</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>774.503132</td>\n",
       "      <td>27.829794</td>\n",
       "      <td>40.109096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsExperience</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>604.822658</td>\n",
       "      <td>24.593027</td>\n",
       "      <td>23.813590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milesFromMetropolis</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>527.651915</td>\n",
       "      <td>22.970576</td>\n",
       "      <td>15.645365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>524.679292</td>\n",
       "      <td>22.905781</td>\n",
       "      <td>15.319152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>414.584386</td>\n",
       "      <td>20.361277</td>\n",
       "      <td>2.508846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>411.528611</td>\n",
       "      <td>20.286092</td>\n",
       "      <td>2.130327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>companyId</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>394.510556</td>\n",
       "      <td>19.862205</td>\n",
       "      <td>-0.003728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model         mse       rmse  percentage_error_increase\n",
       "jobType              Ridge  774.503132  27.829794                  40.109096\n",
       "yearsExperience      Ridge  604.822658  24.593027                  23.813590\n",
       "milesFromMetropolis  Ridge  527.651915  22.970576                  15.645365\n",
       "industry             Ridge  524.679292  22.905781                  15.319152\n",
       "degree               Ridge  414.584386  20.361277                   2.508846\n",
       "major                Ridge  411.528611  20.286092                   2.130327\n",
       "companyId            Ridge  394.510556  19.862205                  -0.003728"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_results_df = pd.DataFrame.from_dict(feature_imp_results, orient='index')\n",
    "feature_imp_results_df.sort_values(by='percentage_error_increase', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature_imp = feature_imp_results_df.groupby('Model')\n",
    "# feature_imp.sort_values(by='percentage_error_increase', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import dill\n",
    "# dill.dump_session('/media/oldmonk/D/submission_notebook_env_before_end_Section3.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict Salaries for Test Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

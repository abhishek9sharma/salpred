{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries Used in Data Preparation\n",
    "import pandas as pd\n",
    "import os\n",
    "debug = True\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load Data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to Load Data in a DataFrame\n",
    "datafolder = '../data/'\n",
    "#print(os.listdir(datafolder))\n",
    "train_features_file_name = 'train_features.csv'\n",
    "train_labels_file_name = 'train_salaries.csv'\n",
    "test_features_file_name = 'test_features.csv'\n",
    "\n",
    "# with open(os.path.join(datafolder, test_features_file_name)) as f:\n",
    "#     x = f.readlines()\n",
    "# print(x[1])\n",
    "train_data_features = pd.read_csv(os.path.join(datafolder, train_features_file_name))\n",
    "train_data_labels = pd.read_csv(os.path.join(datafolder, train_labels_file_name))\n",
    "train_full = pd.merge(train_data_features, train_data_labels, on='jobId',how ='inner')\n",
    "test_data_features = pd.read_csv(os.path.join(datafolder, test_features_file_name))\n",
    "\n",
    "assert(train_full.shape[0] == train_data_features.shape[0])\n",
    "assert(train_full.shape[0] == train_data_labels.shape[0])\n",
    "#train_full.dropna(how ='any', inplace = True)\n",
    "train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Clean/Check Data (Pending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobId                  0\n",
       "companyId              0\n",
       "jobType                0\n",
       "degree                 0\n",
       "major                  0\n",
       "industry               0\n",
       "yearsExperience        0\n",
       "milesFromMetropolis    0\n",
       "salary                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_full.describe()\n",
    "train_full.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 One Hot Encoding : Done for *companyId*, *major*, and *industry* as these variabes are categories and may influence the salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OH_companyId', 'OH_major', 'OH_industry']\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Variables One Hot\n",
    "\n",
    "def one_hot_encoding(c, df):\n",
    "    new_f_name = 'OH_'+ c\n",
    "    df = pd.concat([train_full, pd.get_dummies(df[c], prefix= new_f_name)], axis=1)\n",
    "    return df, new_f_name\n",
    "\n",
    "cat_features_normal = ['companyId', 'major', 'industry']\n",
    "cat_features_normal_new = []\n",
    "for c in cat_features_normal:\n",
    "    train_full, new_f_name = one_hot_encoding(c, train_full)\n",
    "    cat_features_normal_new.append(new_f_name)\n",
    "    \n",
    "    \n",
    "print(cat_features_normal_new)\n",
    "#train_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Ordinal  Encoding : Done for *degree* and *jobType* as these variabes have an inherent order associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pending Visualize data to decide order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORD_jobType', 'ORD_degree']\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Variables Ordered\n",
    "\n",
    "def ordinal_encoding(c, df, lookup):\n",
    "    new_f_name = 'ORD_'+ c\n",
    "    df[new_f_name] =  df[c].map(lookup)\n",
    "    return df, new_f_name\n",
    "\n",
    "degreeOrder = {'BACHELORS':2, 'DOCTORAL':4, 'HIGH_SCHOOL':1, 'MASTERS':3, 'NONE':0}\n",
    "jobTypeOrder = {'CEO':7, 'CFO':6, 'CTO':5, 'VICE_PRESIDENT':4, 'MANAGER':3,'SENIOR':2, 'JUNIOR':1, 'JANITOR':0}\n",
    "\n",
    "cat_features_ordinal = ['jobType', 'degree']\n",
    "cat_features_ordinal_new = []\n",
    "for c in cat_features_ordinal:\n",
    "    train_full, new_f_name = ordinal_encoding(c, train_full, eval(c+'Order'))\n",
    "    cat_features_ordinal_new.append(new_f_name)\n",
    "\n",
    "print(cat_features_ordinal_new)\n",
    "#train_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Shuffle Data and Split into K folds which are used during model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Shuffle Train Data\n",
    "train_full =  train_full.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     2
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split Data into K Folds\n",
    "from sklearn.model_selection import KFold\n",
    "def GetKFoldData(df,k):\n",
    "    folds = {}\n",
    "    kfolds = KFold(n_splits=k, shuffle = True, random_state = 4) \n",
    "    foldidx = 0\n",
    "    for train_idx, test_idx in kfolds.split(df.index):\n",
    "        folds[foldidx] = { 'train': df.iloc[train_idx], 'test':df.iloc[test_idx]}\n",
    "        foldidx+=1\n",
    "    return folds\n",
    "\n",
    "#exp_data_k_folds = GetKFoldData(train_full, 10)\n",
    "#idx_list_org = exp_data_k_folds[0]['test'].index.tolist()\n",
    "#exp_data_k_folds[0]['test'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set(test_data_features.jobType.tolist())\n",
    "# set(test_data_features.degree.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Decide Features to Use and Models to Evaluate (Feature Scaling Pending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1 Features to be Used (Filtered out encoded variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select Features\n",
    "train_features = ['yearsExperience', 'milesFromMetropolis']\n",
    "for f in train_full.columns:\n",
    "    if 'OH' in f or 'ORD' in f:\n",
    "        train_features.append(f)\n",
    "        \n",
    "#train_full[train_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 Regression Models Considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Different Regression Models Evaluated\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "models = {\n",
    "            'LR' :    {'modelobj' :  linear_model.LinearRegression(), 'mse':None, 'rmse':None,\\\n",
    "                                     'tr_time':None,'tst_time':None},\n",
    "    \n",
    "            'Ridge' : {'modelobj' :  linear_model.Ridge(), 'mse':None, 'rmse':None,\\\n",
    "                                     'tr_time':None,'tst_time':None,\\\n",
    "                                     'params' : {'alpha': [i for i in range(1,81,3)]}} ,\n",
    "    \n",
    "            'DT' :    {'modelobj' :  DecisionTreeRegressor(random_state=10), 'mse':None, 'rmse':None, \\\n",
    "                                     'tr_time':None,'tst_time':None, \\\n",
    "                                     'params' : {\n",
    "                                                 'max_depth':[i for i in range(9,12)], \\\n",
    "                                                 'min_samples_leaf' :[i for i in range(10,21,5)]\n",
    "                                                }}#,   \n",
    "    \n",
    "#             'RF' :    {'modelobj' :  RandomForestRegressor(random_state=10), 'mse':None, 'rmse':None, \\\n",
    "#                                      'tr_time':None,'tst_time':None, \\\n",
    "#                                      'params' : {\n",
    "#                                                  'n_estimators':[i for i in range(300,501,100)],\n",
    "#                                                  'max_depth':[i for i in range(9,12)], \n",
    "#                                                  'min_samples_leaf' :[i for i in range(10,21,5)],\n",
    "#                                                  'max_features' : ['log2', 'sqrt']\n",
    "#                                                  }}\n",
    "        \n",
    "            #'GBR' : {'modelobj' :  GradientBoostingRegressor(), 'mse':None, 'rmse':None}\n",
    "         \n",
    "         }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0,
     6,
     36
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions to Evaluate a Model given train and test data\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def EvalModelSplitData(m, model, curr_fold, train_features):\n",
    "    \n",
    "    #Train\n",
    "    curr_fold_X_train = curr_fold['train'][train_features]\n",
    "    curr_fold_X_train_scaled = preprocessing.scale(curr_fold_X_train)\n",
    "    scaler = preprocessing.StandardScaler().fit(curr_fold_X_train)\n",
    "    \n",
    "    curr_fold_y_train = curr_fold['train']['salary'] \n",
    "    \n",
    "    tr_st = time.time()\n",
    "    curr_model = model['modelobj'].fit(curr_fold_X_train_scaled, curr_fold_y_train)\n",
    "    tr_time = time.time() - tr_st\n",
    "    \n",
    "    \n",
    "    #Test\n",
    "    curr_fold_X_test = curr_fold['test'][train_features]\n",
    "    curr_fold_X_test_scaled = scaler.transform(curr_fold_X_test)\n",
    "    curr_fold_y_test = curr_fold['test']['salary']\n",
    "    \n",
    "    tst_st = time.time()\n",
    "    curr_test_predict = curr_model.predict(curr_fold_X_test_scaled)\n",
    "    tst_time = time.time() - tst_st\n",
    "    \n",
    "    #Compute Cost (MSE/RMSE)\n",
    "    curr_fold_mse = MSE(curr_test_predict, curr_fold_y_test)\n",
    "    curr_fold_rmse = curr_fold_mse**0.5\n",
    "    \n",
    "    return curr_fold_mse, curr_fold_rmse, tr_time, tst_time\n",
    "    \n",
    "\n",
    "def GetBestParams(m, model, alldata, train_features, k):\n",
    "    X_train = alldata[train_features]\n",
    "    y_train = alldata['salary']\n",
    "    \n",
    "    X_train_scaled = preprocessing.scale(X_train)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        \n",
    "    \n",
    "    if m in ['Ridge','DT']:\n",
    "        model_search = GridSearchCV(model['modelobj'], model['params'], cv=k, verbose=0, n_jobs=-1,\\\n",
    "                                    scoring ='neg_mean_squared_error')\n",
    "        model_search.fit(X_train_scaled, y_train)\n",
    "        best_model = model_search.best_estimator_\n",
    "        return best_model\n",
    "    elif m in ['RF','GBR']:\n",
    "        model_search = GridSearchCV(model['modelobj'], model['params'],verbose=0, n_jobs=-1,\\\n",
    "                                    scoring ='neg_mean_squared_error')\n",
    "        model_search.fit(X_train_scaled, y_train)\n",
    "        best_model = model_search.best_estimator_\n",
    "        return best_model\n",
    "    else:\n",
    "        return model['modelobj']        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 Run Grid Search on all models to get initial best performing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finding Best Params\n",
      "LR Best Params Found\n",
      "Ridge Finding Best Params\n",
      "Ridge Best Params Found\n",
      "DT Finding Best Params\n",
      "DT Best Params Found\n"
     ]
    }
   ],
   "source": [
    "#Get Model Params Using Grid Search CV\n",
    "\n",
    "def RunExpOnAllData(models, train_features, alldata):\n",
    "    for m in models:\n",
    "        print(m,'Finding Best Params')\n",
    "        models[m]['modelobj'] = GetBestParams(m, models[m], alldata, train_features,5)\n",
    "        print(m,'Best Params Found')\n",
    "        \n",
    "\n",
    "\n",
    "RunExpOnAllData(models, train_features, train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2  Evaluate all models to see what perfoms best on differnt folds created in 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tr_time</th>\n",
       "      <th>tst_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>422.129230</td>\n",
       "      <td>20.545755</td>\n",
       "      <td>20.080592</td>\n",
       "      <td>0.046778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>394.532168</td>\n",
       "      <td>19.862799</td>\n",
       "      <td>5.046307</td>\n",
       "      <td>0.018108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>394.527229</td>\n",
       "      <td>19.862675</td>\n",
       "      <td>1.301643</td>\n",
       "      <td>0.013635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mse       rmse    tr_time  tst_time\n",
       "DT     422.129230  20.545755  20.080592  0.046778\n",
       "LR     394.532168  19.862799   5.046307  0.018108\n",
       "Ridge  394.527229  19.862675   1.301643  0.013635"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find model performance vased on k-fold data created earliers ( See 1.4)\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "def RunExpOnSplitData(kfolddata, models,train_features):\n",
    "    for m in models:\n",
    "        pool = mp.Pool(mp.cpu_count() -1 )\n",
    "        #mse_rmse_results = pool.starmap(EvalModel, [ (models[m], kfolddata[curr_fold], train_features) for curr_fold in kfolddata])\n",
    "        mse_rmse_results = pool.starmap_async(EvalModelSplitData, [(m, models[m], kfolddata[curr_fold], train_features) for curr_fold in kfolddata]).get()\n",
    "        pool.close()\n",
    "    \n",
    "        models[m]['mse'] = sum([i[0] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['rmse'] = sum([i[1] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['tr_time'] = sum([i[2] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['tst_time'] = sum([i[3] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        \n",
    "        #print(m, models[m]['mse'], models[m]['rmse'],models[m]['tr_time'],models[m]['tst_time'], k)              \n",
    "\n",
    "k = 10\n",
    "kfolddata =  GetKFoldData(train_full, k)    \n",
    "RunExpOnSplitData(kfolddata, models, train_features)\n",
    "models_df =  pd.DataFrame.from_dict(models, orient='index')\n",
    "models_df[['mse','rmse','tr_time','tst_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2  Choose the model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge  is the model choosen\n"
     ]
    }
   ],
   "source": [
    "#Choose Model Having the least RMSE on average over k-fold data\n",
    "modelchosen = ('DT',models['DT'])\n",
    "for m in models:\n",
    "    if models[m]['rmse']<modelchosen[1]['rmse']:\n",
    "        modelchosen = (m,models[m])\n",
    "\n",
    "print(modelchosen[0], ' is the model choosen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#modelchosen = ('LR',models['LR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COmmented\n",
    "\n",
    "# curr_model_mse = 0 \n",
    "# curr_model_rmse = 0                 \n",
    "#         for curr_fold in kfolddata:\n",
    "#             curr_fold_mse, curr_fold_rmse = EvalModel(models[m], kfolddata[curr_fold], train_features)\n",
    "#             print(m, curr_fold_mse, curr_fold_rmse)\n",
    "#             curr_model_mse += curr_fold_mse\n",
    "#             curr_model_rmse += curr_fold_rmse\n",
    "\n",
    "#         models[m]['mse']  = curr_model_mse/k\n",
    "#         models[m]['rmse'] = curr_model_rmse/k\n",
    "#         print(m, models[m]['mse'], models[m]['rmse'], k)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Importance w.r.t best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the best performing model I have tried to measure feature importance based on the impact they cause when the feature has been removed. (I have removed the features from the original category and not the encoded ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Features whose importance will be evaluated\n",
    "org_features = ['companyId', 'jobType', 'degree', 'major', 'industry','yearsExperience', 'milesFromMetropolis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Check change in RMSE performance on k-fold data when a feature is excluded\n",
    "feature_imp_results = {}\n",
    "#for m in models:\n",
    "#    modelchosen = (m, models[m])\n",
    "for f in org_features:    \n",
    "    train_features_wo_currf = [of for of in train_features if f not in of]\n",
    "    pool = mp.Pool(mp.cpu_count() -1 )\n",
    "    mse_rmse_results = pool.starmap_async(EvalModelSplitData, [(modelchosen[0], modelchosen[1], kfolddata[curr_fold], train_features_wo_currf) for curr_fold in kfolddata]).get()\n",
    "    pool.close()\n",
    "    if f not in feature_imp_results:\n",
    "        feature_imp_results[f] = {}\n",
    "        feature_imp_results[f]['Model'] = modelchosen[0]\n",
    "        feature_imp_results[f]['mse'] = sum([i[0] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        feature_imp_results[f]['rmse'] = sum([i[1] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        feature_imp_results[f]['percentage_error_increase'] = 100 * (feature_imp_results[f]['rmse'] - modelchosen[1]['rmse'])/modelchosen[1]['rmse']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_results_df = pd.DataFrame.from_dict(feature_imp_results, orient='index')\n",
    "feature_imp_results_df.sort_values(by='percentage_error_increase', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_imp = feature_imp_results_df.groupby('Model')\n",
    "# feature_imp.sort_values(by='percentage_error_increase', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries Used in Data Preparation\n",
    "import pandas as pd\n",
    "import os\n",
    "debug = True\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load Data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to Load Data in a DataFrame\n",
    "datafolder = '../data/'\n",
    "#print(os.listdir(datafolder))\n",
    "train_features_file_name = 'train_features.csv'\n",
    "train_labels_file_name = 'train_salaries.csv'\n",
    "test_features_file_name = 'test_features.csv'\n",
    "\n",
    "# with open(os.path.join(datafolder, test_features_file_name)) as f:\n",
    "#     x = f.readlines()\n",
    "# print(x[1])\n",
    "train_data_features = pd.read_csv(os.path.join(datafolder, train_features_file_name))\n",
    "train_data_labels = pd.read_csv(os.path.join(datafolder, train_labels_file_name))\n",
    "train_full = pd.merge(train_data_features, train_data_labels, on='jobId',how ='inner')\n",
    "test_data_features = pd.read_csv(os.path.join(datafolder, test_features_file_name))\n",
    "\n",
    "assert(train_full.shape[0] == train_data_features.shape[0])\n",
    "assert(train_full.shape[0] == train_data_labels.shape[0])\n",
    "#train_full.dropna(how ='any', inplace = True)\n",
    "train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Clean/Check Data (Pending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobId                  0\n",
       "companyId              0\n",
       "jobType                0\n",
       "degree                 0\n",
       "major                  0\n",
       "industry               0\n",
       "yearsExperience        0\n",
       "milesFromMetropolis    0\n",
       "salary                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_full.describe()\n",
    "train_full.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 One Hot Encoding : Done for *companyId*, *major*, and *industry* as these variabes are categories and may influence the salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OH_companyId', 'OH_major', 'OH_industry']\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Variables One Hot\n",
    "\n",
    "def one_hot_encoding(c, df):\n",
    "    new_f_name = 'OH_'+ c\n",
    "    df = pd.concat([train_full, pd.get_dummies(df[c], prefix= new_f_name)], axis=1)\n",
    "    return df, new_f_name\n",
    "\n",
    "cat_features_normal = ['companyId', 'major', 'industry']\n",
    "cat_features_normal_new = []\n",
    "for c in cat_features_normal:\n",
    "    train_full, new_f_name = one_hot_encoding(c, train_full)\n",
    "    cat_features_normal_new.append(new_f_name)\n",
    "    \n",
    "    \n",
    "print(cat_features_normal_new)\n",
    "#train_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Ordinal  Encoding : Done for *degree* and *jobType* as these variabes have an inherent order associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pending Visualize data to decide order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORD_jobType', 'ORD_degree']\n"
     ]
    }
   ],
   "source": [
    "#Encode Categorical Variables Ordered\n",
    "\n",
    "def ordinal_encoding(c, df, lookup):\n",
    "    new_f_name = 'ORD_'+ c\n",
    "    df[new_f_name] =  df[c].map(lookup)\n",
    "    return df, new_f_name\n",
    "\n",
    "degreeOrder = {'BACHELORS':2, 'DOCTORAL':4, 'HIGH_SCHOOL':1, 'MASTERS':3, 'NONE':0}\n",
    "jobTypeOrder = {'CEO':7, 'CFO':6, 'CTO':5, 'VICE_PRESIDENT':4, 'MANAGER':3,'SENIOR':2, 'JUNIOR':1, 'JANITOR':0}\n",
    "\n",
    "cat_features_ordinal = ['jobType', 'degree']\n",
    "cat_features_ordinal_new = []\n",
    "for c in cat_features_ordinal:\n",
    "    train_full, new_f_name = ordinal_encoding(c, train_full, eval(c+'Order'))\n",
    "    cat_features_ordinal_new.append(new_f_name)\n",
    "\n",
    "print(cat_features_ordinal_new)\n",
    "#train_full.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Shuffle Data and Split into K folds which are used during model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle Train Data\n",
    "train_full =  train_full.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     2
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split Data into K Folds\n",
    "from sklearn.model_selection import KFold\n",
    "def GetKFoldData(df,k):\n",
    "    folds = {}\n",
    "    kfolds = KFold(n_splits=k, shuffle = True, random_state = 4) \n",
    "    foldidx = 0\n",
    "    for train_idx, test_idx in kfolds.split(df.index):\n",
    "        folds[foldidx] = { 'train': df.iloc[train_idx], 'test':df.iloc[test_idx]}\n",
    "        foldidx+=1\n",
    "    return folds\n",
    "\n",
    "#exp_data_k_folds = GetKFoldData(train_full, 10)\n",
    "#idx_list_org = exp_data_k_folds[0]['test'].index.tolist()\n",
    "#exp_data_k_folds[0]['test'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set(test_data_features.jobType.tolist())\n",
    "# set(test_data_features.degree.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Decide Features to Use and Models to Evaluate (Feature Scaling Pending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1 Features to be Used (Filtered out encoded variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select Features\n",
    "train_features = ['yearsExperience', 'milesFromMetropolis']\n",
    "for f in train_full.columns:\n",
    "    if 'OH' in f or 'ORD' in f:\n",
    "        train_features.append(f)\n",
    "        \n",
    "#train_full[train_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 Regression Models Considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Different Regression Models Evaluated\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "models = {\n",
    "            'LR' :    {'modelobj' :  linear_model.LinearRegression(), 'mse':None, 'rmse':None,\\\n",
    "                                     'tr_time':None,'tst_time':None},\n",
    "    \n",
    "            'Ridge' : {'modelobj' :  linear_model.Ridge(), 'mse':None, 'rmse':None,\\\n",
    "                                     'tr_time':None,'tst_time':None,\\\n",
    "                                     'params' : {'alpha': [i for i in range(1,50,2)]}} ,\n",
    "    \n",
    "            'DT' :    {'modelobj' :  DecisionTreeRegressor(random_state=10), 'mse':None, 'rmse':None, \\\n",
    "                                     'tr_time':None,'tst_time':None, \\\n",
    "                                     'params' : {\n",
    "                                                 'max_depth':[i for i in range(9,12)], \\\n",
    "                                                 'min_samples_leaf' :[i for i in range(10,21,5)]\n",
    "                                                }},   \n",
    "    \n",
    "            'RF' :    {'modelobj' :  RandomForestRegressor(random_state=10), 'mse':None, 'rmse':None, \\\n",
    "                                     'tr_time':None,'tst_time':None, \\\n",
    "                                     'params' : {\n",
    "                                                 'n_estimators':[i for i in range(300,501,100)],\n",
    "                                                 'max_depth':[i for i in range(9,12)], \n",
    "                                                 'min_samples_leaf' :[i for i in range(10,21,5)],\n",
    "                                                 'max_features' : ['log2', 'sqrt']\n",
    "                                                 }}\n",
    "        \n",
    "            #'GBR' : {'modelobj' :  GradientBoostingRegressor(), 'mse':None, 'rmse':None},\n",
    "            #'XGB' : {'modelobj' :   XGBClassifier(), 'mse':None, 'rmse':None}\n",
    "         \n",
    "         }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper Functions to Evaluate a Model given train and test data\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def EvalModelSplitData(m, model, curr_fold, train_features):\n",
    "    \n",
    "    #Train\n",
    "    curr_fold_X_train = curr_fold['train'][train_features]\n",
    "    curr_fold_X_train_scaled = preprocessing.scale(curr_fold_X_train)\n",
    "    scaler = preprocessing.StandardScaler().fit(curr_fold_X_train)\n",
    "    \n",
    "    curr_fold_y_train = curr_fold['train']['salary'] \n",
    "    \n",
    "    tr_st = time.time()\n",
    "    curr_model = model['modelobj'].fit(curr_fold_X_train_scaled, curr_fold_y_train)\n",
    "    tr_time = time.time() - tr_st\n",
    "    \n",
    "    \n",
    "    #Test\n",
    "    curr_fold_X_test = curr_fold['test'][train_features]\n",
    "    curr_fold_X_test_scaled = scaler.transform(curr_fold_X_test)\n",
    "    curr_fold_y_test = curr_fold['test']['salary']\n",
    "    \n",
    "    tst_st = time.time()\n",
    "    curr_test_predict = curr_model.predict(curr_fold_X_test_scaled)\n",
    "    tst_time = time.time() - tst_st\n",
    "    \n",
    "    #Compute Cost (MSE/RMSE)\n",
    "    curr_fold_mse = MSE(curr_test_predict, curr_fold_y_test)\n",
    "    curr_fold_rmse = curr_fold_mse**0.5\n",
    "    \n",
    "    return curr_fold_mse, curr_fold_rmse, tr_time, tst_time\n",
    "    \n",
    "\n",
    "def GetBestParams(m, model, alldata, train_features, k):\n",
    "    X_train = alldata[train_features]\n",
    "    y_train = alldata['salary']\n",
    "    \n",
    "    X_train_scaled = preprocessing.scale(X_train)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        \n",
    "    \n",
    "    if m in ['Ridge','DT','RF']:\n",
    "        model_search = GridSearchCV(model['modelobj'], model['params'], cv=k, verbose=0, n_jobs=-1,\\\n",
    "                                    scoring ='neg_mean_squared_error')\n",
    "        model_search.fit(X_train_scaled, y_train)\n",
    "        best_model = model_search.best_estimator_\n",
    "        return best_model\n",
    "    else:\n",
    "        return model['modelobj']        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 Run Grid Search on all models to get initial best performing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Get Model Params Using Grid Search CV\n",
    "\n",
    "def RunExpOnAllData(models, train_features, alldata):\n",
    "    for m in models:\n",
    "        models[m]['modelobj'] = GetBestParams(m, models[m], alldata, train_features,5)\n",
    "        print(m,'Initialized')\n",
    "        \n",
    "\n",
    "\n",
    "RunExpOnAllData(models, train_features, train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2  Eval all models to see what perfoms best on differnt folds created in 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Find Best Performing Model Based on Performance on Ten Fold Created in 1.4\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "def RunExpOnSplitData(k, models,train_features):\n",
    "    kfolddata =  GetKFoldData(train_full, k)\n",
    "    for m in models:\n",
    "        pool = mp.Pool(mp.cpu_count() -1 )\n",
    "        #mse_rmse_results = pool.starmap(EvalModel, [ (models[m], kfolddata[curr_fold], train_features) for curr_fold in kfolddata])\n",
    "        mse_rmse_results = pool.starmap_async(EvalModelSplitData, [(m, models[m], kfolddata[curr_fold], train_features) for curr_fold in kfolddata]).get()\n",
    "        pool.close()\n",
    "    \n",
    "        models[m]['mse'] = sum([i[0] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['rmse'] = sum([i[1] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['tr_time'] = sum([i[2] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        models[m]['tst_time'] = sum([i[3] for i in mse_rmse_results])/len(mse_rmse_results)\n",
    "        \n",
    "        print(m, models[m]['mse'], models[m]['rmse'],models[m]['tr_time'],models[m]['tst_time'], k)              \n",
    "\n",
    "RunExpOnSplitData(10, models, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COmmented\n",
    "\n",
    "# curr_model_mse = 0 \n",
    "# curr_model_rmse = 0                 \n",
    "#         for curr_fold in kfolddata:\n",
    "#             curr_fold_mse, curr_fold_rmse = EvalModel(models[m], kfolddata[curr_fold], train_features)\n",
    "#             print(m, curr_fold_mse, curr_fold_rmse)\n",
    "#             curr_model_mse += curr_fold_mse\n",
    "#             curr_model_rmse += curr_fold_rmse\n",
    "\n",
    "#         models[m]['mse']  = curr_model_mse/k\n",
    "#         models[m]['rmse'] = curr_model_rmse/k\n",
    "#         print(m, models[m]['mse'], models[m]['rmse'], k)\n",
    "#         print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
